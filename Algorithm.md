# 정렬 알고리즘
## 안정 정렬(Stable) vs 불안정 정렬(Unstable)
* 안정 정렬
	* 정렬할 요소 중에서 중복된 값의 위치가 정렬되기 전, 후로 동일한 정렬 알고리즘
	* 중복된 요소가 있어도 항상 동일한 결과를 보이는 장점이 있다.
	* 삽입 정렬, 병합 정렬, 버블 정렬
* 불안정 정렬
	* 정렬할 요소 중에서 중복된 값의 위치가 정렬되기 전, 후로 다른 정렬 알고리즘
	* 퀵정렬, 선택 정렬, 계수 정렬

## In-place 정렬
* 정렬 시 추가적인 메모리 공간이 거의 필요하지 않는 정렬 알고리즘
* In-place 정렬
	* 삽입 정렬
	* 선택 정렬
	* 버블 정렬
	* 셸 정렬
	* 힙 정렬
	* 퀵 정렬
* Not In-place 정렬
	* 병합 정렬
	* 계수 정렬
	* 기수 정렬
	* 버킷 정렬

## 분할-정복(Devide-Conquer)
* 현재 주어진 문제를 여러개의 작은 문제로 나누어 해결한 다음 결과를 종합하여 전체 문제를 푸는 방법

## 거품 정렬
* 처음부터 끝까지 순차적으로 현재와 다음 요소와 비교하여 정렬하는 알고리즘
* 1회전이 끝날 때마다 가장 큰 요소가 맨 뒤로 가게 되고, 해당 요소는 제외된다.
* 교환(swap) 연산이 많이 발생한다.
* in-place, stable 정렬이다.
* 시간 복잡도
	* 최선 : O(n^2)
	* 평균 : O(n^2)
	* 최악 : O(n^2)
* 공간 복잡도
	* O(n)

## 선택 정렬
* 배열의 위치를 미리 정하고, 해당 위치에 올 요소를 선택하여 정렬하는 알고리즘
* 정렬되지 않은 부분에서 최소값을 찾고 맨 앞의 요소와 교체 후 제외한다.
* in-place, unstable 정렬
* 시간 복잡도
	* 최선 : O(n^2)
	* 평균 : O(n^2)
	* 최악 : O(n^2)
* 공간 복잡도
	* O(n)

## 삽입 정렬
* 2번째 요소부터 시작해서 정렬된 부분인 현재 요소 앞에서 시작하여 삽입할 위치를 찾고, 뒷 부분 요소들을 한칸씩 뒤로 옮겨 자리를 만들어 삽입해 정렬하는 알고리즘
* 거의 정렬되어 있는 요소들을 정렬할 때 효율적이다. -> O(n)
* 선택 정렬과 달리 필요한 부분(현재 요소 앞에서부터 자신보다 큰 값들만 비교함)만 탐색한다.
* in-place, stable 정렬
* 시간 복잡도
	* 최선 : O(n)
	* 평균 : O(n^2)
	* 최악 : O(n^2)
* 공간 복잡도
	* O(n)

## 퀵 정렬
* 분할 정복을 사용하는 정렬 알고리즘
* 현재 요소 중에서 기준이 될 요소(pivot)를 정한 뒤, pivot을 기준으로 앞에는 pivot보다 작은 값들이 위치하도록, 뒤에는 pivot보다 큰 값들이 위치하도록 한다. (분할, Devide)
* 분할된 두 요소를 재귀적으로 앞의 과정을 거쳐서 정렬시킨다.
* 재귀가 한번 호출될 때 마다, 최소 한 개 pivot의 위치가 정해지므로 알고리즘이 무조건 끝나는 것을 보장한다.
* pivot에 따라 균등하지 않는 크기로 분할될 수 있다.
* pivot값이 최소, 최대일 경우 O(n^2)이 걸린다.
* in-place, unstable 정렬
* 시간 복잡도
	* 최선 : O(nlogn)
	* 평균 : O(nlogn)
	* 최악 : O(n^2) -> 정렬할 배열이 오름차순 또는 내림차순일 경우
* 공간 복잡도
	* O(n)	

## 병합 정렬
* 분할 정복을 사용하는 정렬 알고리즘
* 배열의 크기가 1일 때까지 반으로 분할한 다음, 분할된 배열을 합치면서 정렬하는 알고리즘
* 합쳐질 두 배열들은 이미 정렬된 상태이므로, 두 배열을 순차적으로 비교해 하나로 합칠 수 있다.
* Linked-List를 정렬할 때 효율적이다.(합칠 두 배열을 순차적으로 비교해 하나로 합치기 때문)
* not in-place 정렬, stable 정렬
* 시간 복잡도
	* 최선 : O(nlogn)
	* 평균 : O(nlogn)
	* 최악 : O(nlogn)
* 공간 복잡도
	* O(n)

## 힙 정렬
* 힙을 이용해 정렬하는 알고리즘
* in-place, unstable 정렬
* heapify 과정을 거쳐서 정렬을 위한 힙을 만든다.
* 힙을 구성하기 때문에, 가장 큰 값(Max 힙)이나 가장 작은 값(Min 힙)을 구할 때 좋다.
* 시간 복잡도
	* 최선 : O(nlogn)
	* 평균 : O(nlogn)
	* 최악 : O(nlogn)

## 기수 정렬

## 계수 정렬
* 정렬할 배열의 모든 요소들을 탐색해 값이 나온 횟수를 계산한다.
* 정렬할 배열의 요소 중에서 가장 작은 값부터 큰 값까지 조회 횟수를 이용해 정렬된 배열을 만든다.
* 정렬할 요소의 최대값이 특정 범위 내에 있어야만 사용가능하다.
* 정렬할 요소의 최대값에 따라 count 배열이 커질 수 있다.
* 시간 복잡도
	* 최선 : O(n + k) (n은 정렬할 요소의 개수, k는 데이터의 최대값)
	* 평균 : O(n + k)
	* 최악 : O(n + k)

## 이분 탐색
* 전체를 순차적으로 탐색하면 O(n)이 걸린다. 하지만, 이분 탐색을 사용하면 O(logn)이 걸린다.
* 이분 탐색을 사용하기 위해서는 배열이 정렬되어 있어야한다.
* 탐색할 부분에서 가운데 요소를 비교해 탐색할 요소보다 크면 오른쪽 부분만 탐색하고, 작으면 왼쪽 부분만 탐색한다.
* 탐색 과정보다 정렬을 위한 작업의 시간 복잡도가 더 높다.

# 해시
## 해시 함수
* 임의의 길이의 데이터를 고정된 길이의 데이터로 변환하는 함수
* 동일한 입력값에 대해서 항상 동일한 출력값을 반환한다.

## 해싱
* key를 해시 함수를 이용해 해시값으로 변환하는 과정

## 해시 충돌
* 서로 다른 key가 동일한 인덱스 값(해시 함수의 적용 결과)을 가지는 경우이다.
	* 해결 방법
		* 체이닝
			* 버킷을 연결리스트로 관리하고, 새로운 값을 저장한다.
			* n개의 데이터가 모두 해시 충돌이 발생하면, 조회하는데 O(n)이 걸린다.
		* 개방 주소법
			* 기존에 비어있는 버킷을 활용해 새로운 값을 저장한다.
			* 종류
				* 선형 조사법(Linear Probing)
					* 현재 버킷에서 고정 폭씩 이동하여 새로운 값을 저장한다.
				* 이차 조사법(Quadratic Probing)
					* 현재 버킷에서 k^2(k=1, 2, 3 ...)씩 이동하여 새로운 값을 저장한다.
				* 이중 해싱(Double Hasing Probing)
					* 해싱된 값을 한번 더 해싱하여 인덱스 값 사용한다.
					* 
## 해시 테이블
* 해시를 이용해 생성한 key와 매핑되는 value를 저장하는 자료구조
* key에 해시 함수를 적용한 값을 인덱스로 사용해 value를 저장한다.
* 값이 저장되는 장소를 버킷(슬롯)이라고 한다.
* 삽입/삭제/조회하는데 시간 복잡도는 O(1)이다.
	


















